{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-07-30T19:49:00.734239Z","iopub.status.busy":"2024-07-30T19:49:00.733033Z","iopub.status.idle":"2024-07-30T19:49:00.755585Z","shell.execute_reply":"2024-07-30T19:49:00.754392Z","shell.execute_reply.started":"2024-07-30T19:49:00.734188Z"},"trusted":true},"outputs":[{"data":{"text/plain":["['data\\\\gender_submission.csv', 'data\\\\test.csv', 'data\\\\train.csv']"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import numpy as np  \n","import pandas as pd \n","import os\n","\n","\n","data = []\n","\n","for dirpath, dirnames, filenames in os.walk('data\\\\'):\n","    for filename in filenames:\n","        data.append(os.path.join('data', filename))\n","\n","data\n"]},{"cell_type":"markdown","metadata":{},"source":["### Data check and organization"]},{"cell_type":"code","execution_count":81,"metadata":{"execution":{"iopub.execute_input":"2024-07-30T19:49:02.841297Z","iopub.status.busy":"2024-07-30T19:49:02.840832Z","iopub.status.idle":"2024-07-30T19:49:02.859421Z","shell.execute_reply":"2024-07-30T19:49:02.857749Z","shell.execute_reply.started":"2024-07-30T19:49:02.841259Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Ticket</th>\n","      <th>Fare</th>\n","      <th>Cabin</th>\n","      <th>Embarked</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Braund, Mr. Owen Harris</td>\n","      <td>male</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>A/5 21171</td>\n","      <td>7.2500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n","      <td>female</td>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>PC 17599</td>\n","      <td>71.2833</td>\n","      <td>C85</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>Heikkinen, Miss. Laina</td>\n","      <td>female</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>STON/O2. 3101282</td>\n","      <td>7.9250</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n","      <td>female</td>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>113803</td>\n","      <td>53.1000</td>\n","      <td>C123</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Allen, Mr. William Henry</td>\n","      <td>male</td>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>373450</td>\n","      <td>8.0500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>886</th>\n","      <td>887</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>Montvila, Rev. Juozas</td>\n","      <td>male</td>\n","      <td>27.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>211536</td>\n","      <td>13.0000</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>887</th>\n","      <td>888</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Graham, Miss. Margaret Edith</td>\n","      <td>female</td>\n","      <td>19.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>112053</td>\n","      <td>30.0000</td>\n","      <td>B42</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>888</th>\n","      <td>889</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n","      <td>female</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>W./C. 6607</td>\n","      <td>23.4500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>889</th>\n","      <td>890</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Behr, Mr. Karl Howell</td>\n","      <td>male</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>111369</td>\n","      <td>30.0000</td>\n","      <td>C148</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>890</th>\n","      <td>891</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Dooley, Mr. Patrick</td>\n","      <td>male</td>\n","      <td>32.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>370376</td>\n","      <td>7.7500</td>\n","      <td>NaN</td>\n","      <td>Q</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>891 rows Ã— 12 columns</p>\n","</div>"],"text/plain":["     PassengerId  Survived  Pclass  \\\n","0              1         0       3   \n","1              2         1       1   \n","2              3         1       3   \n","3              4         1       1   \n","4              5         0       3   \n","..           ...       ...     ...   \n","886          887         0       2   \n","887          888         1       1   \n","888          889         0       3   \n","889          890         1       1   \n","890          891         0       3   \n","\n","                                                  Name     Sex   Age  SibSp  \\\n","0                              Braund, Mr. Owen Harris    male  22.0      1   \n","1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n","2                               Heikkinen, Miss. Laina  female  26.0      0   \n","3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n","4                             Allen, Mr. William Henry    male  35.0      0   \n","..                                                 ...     ...   ...    ...   \n","886                              Montvila, Rev. Juozas    male  27.0      0   \n","887                       Graham, Miss. Margaret Edith  female  19.0      0   \n","888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n","889                              Behr, Mr. Karl Howell    male  26.0      0   \n","890                                Dooley, Mr. Patrick    male  32.0      0   \n","\n","     Parch            Ticket     Fare Cabin Embarked  \n","0        0         A/5 21171   7.2500   NaN        S  \n","1        0          PC 17599  71.2833   C85        C  \n","2        0  STON/O2. 3101282   7.9250   NaN        S  \n","3        0            113803  53.1000  C123        S  \n","4        0            373450   8.0500   NaN        S  \n","..     ...               ...      ...   ...      ...  \n","886      0            211536  13.0000   NaN        S  \n","887      0            112053  30.0000   B42        S  \n","888      2        W./C. 6607  23.4500   NaN        S  \n","889      0            111369  30.0000  C148        C  \n","890      0            370376   7.7500   NaN        Q  \n","\n","[891 rows x 12 columns]"]},"execution_count":81,"metadata":{},"output_type":"execute_result"}],"source":["gender_submission_path, test_path, train_path = data\n","\n","\n","train = pd.read_csv(train_path)\n","\n","test = pd.read_csv(test_path)\n","\n","\n","train"]},{"cell_type":"markdown","metadata":{},"source":["### Finding and filling nan values"]},{"cell_type":"code","execution_count":82,"metadata":{"execution":{"iopub.execute_input":"2024-07-30T19:49:45.501840Z","iopub.status.busy":"2024-07-30T19:49:45.501410Z","iopub.status.idle":"2024-07-30T19:49:45.521279Z","shell.execute_reply":"2024-07-30T19:49:45.519855Z","shell.execute_reply.started":"2024-07-30T19:49:45.501806Z"},"trusted":true},"outputs":[],"source":["train['Age'].isna().sum()\n","train['Cabin'].isna().sum()\n","train['Embarked'].isna().sum()\n","\n","#print(train['Age'].value_counts(dropna=False))\n","train['Age'].describe()\n","#Age mean is 29.699118 so i'll replace all nan's in Age column with this value,\n","#don't know if this is the right move, buti know it's better than zero\n","\n","train['Cabin'].value_counts(dropna=False)\n","#CHANGE OF PLANS, I DROP ALL THE COLUMNS WHERE CABIN IS NAN \n","train = train.dropna(subset=['Cabin'])\n","#still don't know what to do with this one theres a lot of nans 687 out of 891\n","#as of right now i'll just ignore this column even tho it seems important.\n"," \n","train['Embarked'].value_counts(dropna=False)\n","#theres only 2 nans so im probably gonna drop the records, it's nt a big loss\n","train = train.dropna(subset=['Embarked'])\n","\n","\n","\n","train = train.fillna({'Age':29.699118})"]},{"cell_type":"markdown","metadata":{},"source":["### X and Y extraction"]},{"cell_type":"code","execution_count":83,"metadata":{"execution":{"iopub.execute_input":"2024-07-30T19:49:48.568185Z","iopub.status.busy":"2024-07-30T19:49:48.567717Z","iopub.status.idle":"2024-07-30T19:49:48.583024Z","shell.execute_reply":"2024-07-30T19:49:48.581579Z","shell.execute_reply.started":"2024-07-30T19:49:48.568150Z"},"trusted":true},"outputs":[{"data":{"text/plain":["PassengerId    202\n","Pclass         202\n","Name           202\n","Sex            202\n","Age            202\n","SibSp          202\n","Parch          202\n","Ticket         202\n","Fare           202\n","Cabin          202\n","Embarked       202\n","dtype: int64"]},"execution_count":83,"metadata":{},"output_type":"execute_result"}],"source":["y = train['Survived']\n","\n","# all columns\n","x_columns = ['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n","\n","# Ignoring Cabin\n","#x_columns = ['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Embarked']\n","\n","X_pre_encoding = train[x_columns]\n","X_pre_encoding.isna().sum()\n","X_pre_encoding.count()"]},{"cell_type":"markdown","metadata":{},"source":["### name and ticket label encoding, one hot encoding"]},{"cell_type":"code","execution_count":84,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Pclass</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Fare</th>\n","      <th>Sex_female</th>\n","      <th>Sex_male</th>\n","      <th>Embarked_C</th>\n","      <th>Embarked_Q</th>\n","      <th>...</th>\n","      <th>Cabin_E8</th>\n","      <th>Cabin_F E69</th>\n","      <th>Cabin_F G63</th>\n","      <th>Cabin_F G73</th>\n","      <th>Cabin_F2</th>\n","      <th>Cabin_F33</th>\n","      <th>Cabin_F38</th>\n","      <th>Cabin_F4</th>\n","      <th>Cabin_G6</th>\n","      <th>Cabin_T</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>71.2833</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>...</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>53.1000</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>...</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>7</td>\n","      <td>1</td>\n","      <td>54.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>51.8625</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>...</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>11</td>\n","      <td>3</td>\n","      <td>4.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>16.7000</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>...</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>12</td>\n","      <td>1</td>\n","      <td>58.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>26.5500</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>...</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>871</th>\n","      <td>872</td>\n","      <td>1</td>\n","      <td>47.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>52.5542</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>...</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>872</th>\n","      <td>873</td>\n","      <td>1</td>\n","      <td>33.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>5.0000</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>...</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>879</th>\n","      <td>880</td>\n","      <td>1</td>\n","      <td>56.0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>83.1583</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>...</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>887</th>\n","      <td>888</td>\n","      <td>1</td>\n","      <td>19.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>30.0000</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>...</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>889</th>\n","      <td>890</td>\n","      <td>1</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>30.0000</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>...</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>202 rows Ã— 157 columns</p>\n","</div>"],"text/plain":["     PassengerId  Pclass   Age  SibSp  Parch     Fare  Sex_female  Sex_male  \\\n","1              2       1  38.0      1      0  71.2833        True     False   \n","3              4       1  35.0      1      0  53.1000        True     False   \n","6              7       1  54.0      0      0  51.8625       False      True   \n","10            11       3   4.0      1      1  16.7000        True     False   \n","11            12       1  58.0      0      0  26.5500        True     False   \n","..           ...     ...   ...    ...    ...      ...         ...       ...   \n","871          872       1  47.0      1      1  52.5542        True     False   \n","872          873       1  33.0      0      0   5.0000       False      True   \n","879          880       1  56.0      0      1  83.1583        True     False   \n","887          888       1  19.0      0      0  30.0000        True     False   \n","889          890       1  26.0      0      0  30.0000       False      True   \n","\n","     Embarked_C  Embarked_Q  ...  Cabin_E8  Cabin_F E69  Cabin_F G63  \\\n","1          True       False  ...     False        False        False   \n","3         False       False  ...     False        False        False   \n","6         False       False  ...     False        False        False   \n","10        False       False  ...     False        False        False   \n","11        False       False  ...     False        False        False   \n","..          ...         ...  ...       ...          ...          ...   \n","871       False       False  ...     False        False        False   \n","872       False       False  ...     False        False        False   \n","879        True       False  ...     False        False        False   \n","887       False       False  ...     False        False        False   \n","889        True       False  ...     False        False        False   \n","\n","     Cabin_F G73  Cabin_F2  Cabin_F33  Cabin_F38  Cabin_F4  Cabin_G6  Cabin_T  \n","1          False     False      False      False     False     False    False  \n","3          False     False      False      False     False     False    False  \n","6          False     False      False      False     False     False    False  \n","10         False     False      False      False     False      True    False  \n","11         False     False      False      False     False     False    False  \n","..           ...       ...        ...        ...       ...       ...      ...  \n","871        False     False      False      False     False     False    False  \n","872        False     False      False      False     False     False    False  \n","879        False     False      False      False     False     False    False  \n","887        False     False      False      False     False     False    False  \n","889        False     False      False      False     False     False    False  \n","\n","[202 rows x 157 columns]"]},"execution_count":84,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.preprocessing import LabelEncoder\n","\n","def encode(df):\n","    encoder = LabelEncoder()\n","    #df.loc[:,'names_encoded'] = encoder.fit_transform(df['Name'])\n","\n","    #df.loc[:,'ticket_encoded'] = encoder.fit_transform(df['Ticket'])\n","\n","    df = df.drop(columns=['Name', 'Ticket'])\n","\n","    df = pd.get_dummies(df, columns=['Sex', 'Embarked', 'Cabin'])\n","\n","    return df\n","\n","\n","X = encode(X_pre_encoding)\n","\n","X"]},{"cell_type":"markdown","metadata":{},"source":["### exchanging cabin names between train data and test data, encoding test data"]},{"cell_type":"code","execution_count":85,"metadata":{},"outputs":[],"source":["test = encode(test)"]},{"cell_type":"code","execution_count":86,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["76\n","146\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\damia\\AppData\\Local\\Temp\\ipykernel_7064\\717453363.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test[cab] = False\n","C:\\Users\\damia\\AppData\\Local\\Temp\\ipykernel_7064\\717453363.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test[cab] = False\n","C:\\Users\\damia\\AppData\\Local\\Temp\\ipykernel_7064\\717453363.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test[cab] = False\n","C:\\Users\\damia\\AppData\\Local\\Temp\\ipykernel_7064\\717453363.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test[cab] = False\n","C:\\Users\\damia\\AppData\\Local\\Temp\\ipykernel_7064\\717453363.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test[cab] = False\n","C:\\Users\\damia\\AppData\\Local\\Temp\\ipykernel_7064\\717453363.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test[cab] = False\n","C:\\Users\\damia\\AppData\\Local\\Temp\\ipykernel_7064\\717453363.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test[cab] = False\n","C:\\Users\\damia\\AppData\\Local\\Temp\\ipykernel_7064\\717453363.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test[cab] = False\n","C:\\Users\\damia\\AppData\\Local\\Temp\\ipykernel_7064\\717453363.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test[cab] = False\n","C:\\Users\\damia\\AppData\\Local\\Temp\\ipykernel_7064\\717453363.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test[cab] = False\n","C:\\Users\\damia\\AppData\\Local\\Temp\\ipykernel_7064\\717453363.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test[cab] = False\n","C:\\Users\\damia\\AppData\\Local\\Temp\\ipykernel_7064\\717453363.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test[cab] = False\n","C:\\Users\\damia\\AppData\\Local\\Temp\\ipykernel_7064\\717453363.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test[cab] = False\n","C:\\Users\\damia\\AppData\\Local\\Temp\\ipykernel_7064\\717453363.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test[cab] = False\n"]}],"source":["test_cabins = [col for col in test.columns if col.startswith('Cabin')] \n","train_cabins = [col for col in X.columns if col.startswith('Cabin')] \n","\n","\n","print(len(test_cabins))\n","print(len(train_cabins))\n","\n","\n","for cab in test_cabins:\n","    if cab not in train_cabins:\n","        X[cab] = False\n","        train_cabins.append(cab)\n","        \n","for cab in train_cabins:\n","    if cab not in test_cabins:\n","        test[cab] = False\n"]},{"cell_type":"markdown","metadata":{},"source":["### sorting columns and last check"]},{"cell_type":"code","execution_count":87,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["196\n","196\n"]}],"source":["test = test.sort_index(axis=1)\n","X = X.sort_index(axis=1)\n","\n","test.to_csv('test')\n","X.to_csv('X')\n","\n","print(len(test.columns))\n","print(len(X.columns))"]},{"cell_type":"markdown","metadata":{},"source":["### Creating model and fitting data"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-07-30T19:49:55.991204Z","iopub.status.busy":"2024-07-30T19:49:55.990758Z","iopub.status.idle":"2024-07-30T19:49:56.010465Z","shell.execute_reply":"2024-07-30T19:49:56.009157Z","shell.execute_reply.started":"2024-07-30T19:49:55.991164Z"},"trusted":true},"outputs":[],"source":["from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier # type: ignore\n","\n","model = DecisionTreeRegressor(random_state = 1)\n","\n","model.fit(X, y)"]},{"cell_type":"markdown","metadata":{},"source":["### testing the model - first prediction"]},{"cell_type":"code","execution_count":89,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["418\n","[0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1]\n"]}],"source":["results = model.predict(test)\n","\n","results_int = []\n","for value in results:\n","    results_int.append(int(value))\n","\n","print(len(results_int))\n","print(results_int)\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["### exporting results into a CSV file"]},{"cell_type":"code","execution_count":90,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\damia\\AppData\\Local\\Temp\\ipykernel_7064\\512122877.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  prediciton_df['Survived'] = results_int\n"]}],"source":["def export_results(prediciton_df):\n","    \n","    data = []\n","    temp_data = []\n","\n","    for dirpath, dirnames, filenames in os.walk('submissions\\\\'):\n","        for filename in filenames:\n","            data.append(os.path.join('submissions', filename))\n","            temp_data.append(filename.removesuffix('.csv'))\n","\n","    name_split = temp_data[-1].split('_')\n","    #print(data)\n","    \n","    \n","    new_sub_name = ''.join(['submissions\\\\submission_', str(int(name_split[-1]) + 1), '.csv'])\n","    data.append(new_sub_name)\n","    \n","    #print(new_sub_name)\n","    prediciton_df['Survived'] = results_int\n","    prediciton_df.to_csv(path_or_buf=new_sub_name, columns=['PassengerId', 'Survived'], index=False)\n","    \n","    return data\n","    \n","submissions_list = export_results(test)"]},{"cell_type":"markdown","metadata":{},"source":["### additional functions to compare submisions"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["0"]},"execution_count":108,"metadata":{},"output_type":"execute_result"}],"source":["def comapre_submissions(sub1, sub2):\n","    sub_a = pd.read_csv(sub1)\n","    sub_b = pd.read_csv(sub2)\n","    \n","    different_predictions = 0\n","    \n","    for a, b in zip(sub_a['Survived'], sub_b['Survived']):\n","        if a != b: different_predictions += 1\n","        \n","    return different_predictions\n","    \n","    \n","#comapre_submissions(submissions_list[1], submissions_list[3])    "]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":26502,"sourceId":3136,"sourceType":"competition"}],"dockerImageVersionId":30746,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":4}
